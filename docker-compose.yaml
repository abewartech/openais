version: "3.7"
#===============================
# Compose extension fields
#===============================
x-logging:
  &default-logging
      driver: json-file
      options:
        max-size: 10m

#===============================
services: 
#===============================
  # file_reader:
  # # Reads all AIS files stored in the mounted partition and places them onto the 
  # # AIS pipeline (or does a direct insertion into the DB if easier)
  #   image: <image>/<image>:${FILEREADER_TAG}
  #   container_name: file_reader
  #   command: <run time commands>
  #   restart: unless-stopped
  #   env_file:
  #     - .env
  #   depends_on:
  #     - rabbit
  #   networks:
  #     - back_end
  #   logging: *default-logging
  #   volumes:
  #     volume1:/where/to/mnt/ 

  ais_i_mov:
  # Connects to raw AIS message server and streams and parses
  # raw AIS messages onto the pipeline.
    image: registry.gitlab.com/openais/processing/ais-i-mov:${AISIMOV_TAG}
    container_name: ais_i_mov
    command: python /usr/local/ais_i_mov/main.py -ll 'INFO'
    env_file:
      - .env
    restart: unless-stopped
    depends_on:
      - rabbitmq
    networks:
      - back_end 
    logging: *default-logging 
    volumes:
      - ./volumes/ais_logs/:${LOG_DIR}

  rabbitmq:
  # RabbitMQ message broker. 
    image: rabbitmq:${RABBIT_TAG}
    container_name: rabbitmq 
    healthcheck:
      test: rabbitmq-diagnostics -q ping
      interval: 30s
      timeout: 30s
      retries: 3
    # restart: unless-stopped
    restart: always
    environment: 
        RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER}
        RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS}
    networks:
      - back_end
    ports:
      - ${RABBIT_MANAGE_PORT}:15672
    logging: *default-logging

    ulimits:
      nproc: 65535
      nofile:
        soft: 20000
        hard: 40000  
    volumes:
      - rabbit_data_store:/var/lib/rabbitmq
      - rabbit_etc_store:/etc/rabbitmq

  # ais_filter:
  # # Drops AIS messages that are too close in time/space to 
  # # previous messages from same ship. 
  #   image: <image>/<image>:${SERVICE2_DOCKER_TAG}
  #   container_name: <service name>
  #   command:
  #   restart: unless-stopped
  #   networks:
  #     - back_end
  #   ports:
  #     - ${SERVICE2_PORT}:<container_port>
  #   logging: *default-logging
  #   volumes:
  #     volume2:/where/to/mnt/
  
  ais_decoder:
  # Decodes the raw AIS messages 
    image: registry.gitlab.com/openais/processing/ais_decoder:${DECODER_TAG}
    container_name: ais_decoder
    command: python /usr/local/ais_decoder/main.py -ll 'INFO'
    restart: unless-stopped
    env_file:
      - .env
    depends_on:
      - rabbitmq
    networks:
      - back_end 
    logging: *default-logging 
     
  db_inserter:
  # Does bulk inserts into the DB from AIS pipeline
    image: registry.gitlab.com/openais/processing/db-sink:${INSERTER_TAG}
    container_name: db_inserter
    command: python /usr/local/db-sink/main.py -ll 'INFO'
    restart: unless-stopped
    env_file:
      - .env
    depends_on:
      - rabbitmq
      - database
    networks:
      - back_end
    logging: *default-logging
    volumes:
      - /etc/localtime:/etc/localtime:ro

  database:
  # High availablity version of PG with
  # Timescaledb and PostGIS extensions installed.
  # https://github.com/timescale/timescaledb-docker-ha
    image: registry.gitlab.com/openais/processing/integrated-database:${DATABASE_TAG}
    container_name: database
    user: ${UID}:${GID}
    shm_size: 4g
    command: postgres -c shared_preload_libraries=timescaledb
    restart: unless-stopped
    networks:
      - back_end
    ports:
      - ${DB_EXT_PORT}:5432
    logging: *default-logging
    healthcheck:
      test:
        - CMD-SHELL
        - '[ -f /home/postgres/pgdata/data/ready ]'
        - pg_isready --username=${POSTGRES_USER} --dbname=${POSTGRES_DB}
      start_period: 10m # needs a long start period when downloading shapes during initialization
      interval: 1m
      timeout: 5s
      retries: 5
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${DB_NAME}
      - POSTGRES_UID=${UID}
      - POSTGRES_GID=${GID}
      - FETCH_GEOM=${FETCH_GEOM}
    volumes:
    # Volume commented out to test building of DB. 
    # Uncomment when requiring persistance 
      # - ${DB_VOLUME_PATH}:/home/postgres/pgdata/data
      - ${GEOM_VOLUME_PATH}:/tmp/shapes:Z
      - db_data_store:/home/postgres/pgdata/data 

  featserv: 
    image: pramsey/pg_featureserv:${PGFEATSERV_TAG}
    container_name: featserv
    restart: unless-stopped
    # command: "--config /app/config.toml"
    depends_on:
      database:
        condition: service_healthy
    networks:
      - back_end
    ports:
      - ${API_PORT}:9000
    logging: *default-logging
    environment:
      # - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@database/${DB_NAME}
      - DATABASE_URL=postgresql://${API_USER}:${API_PW}@database/${DB_NAME}
      - PGFS_METADATA_TITLE=OpenAIS
      - PGFS_METADATA_DESCRIPTION="OpenAIS Feature Server"
      - PGFS_WEBSITE_BASEMAPURL=https://maps.wikimedia.org/osm-intl/{z}/{x}/{y}.png
      - PGFS_PAGING_LIMITDEFAULT=1000
      - PGFS_PAGING_LIMITMAX=10000
      - PGFS_SERVER_CORSORIGINS="*"
    # volumes:
      # - ./config/feat_serv_config.toml:/app/config.toml:ro

#===============================
volumes:
#===============================
  rabbit_etc_store:
  rabbit_data_store:
  db_data_store:   

#===============================
networks:
#===============================
  # Network for front end access/management
  front_end:
  # Network for data pipeline
  back_end: